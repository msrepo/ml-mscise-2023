{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlQojCaPfXJ7ua70o+3Quh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msrepo/ml-mscise-2023/blob/master/model_evaluation/nested_cross_validation_for_algorithm_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Notebook by: **Sebastian Raschka**\n",
        "\n",
        "## A \"nested cross-validation for algorithm selection\" example using scikit-learn"
      ],
      "metadata": {
        "id": "jho26One5p0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mlxtend"
      ],
      "metadata": {
        "id": "kPUEVzWI6HMD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.utils._testing import ignore_warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from scipy.optimize.linesearch import LineSearchWarning\n",
        "\n",
        "warnings.simplefilter(\"ignore\",ConvergenceWarning)\n",
        "warnings.simplefilter(\"ignore\",LineSearchWarning)\n",
        "\n",
        "import numpy as np\n",
        "from mlxtend.data import mnist_data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "\n",
        "np.random.seed(1)\n",
        "random.seed(1)"
      ],
      "metadata": {
        "id": "np8wNpFd6Nsy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and split the dataset\n",
        "# Note that this is a small (stratified) subset\n",
        "# of MNIST; it consists of 5000 samples only, that is,\n",
        "# 10% of the original MNIST dataset\n",
        "X, y = mnist_data()\n",
        "X = X.astype(np.float32)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    train_size =0.8,\n",
        "                                                    random_state=1,\n",
        "                                                    stratify=y)\n",
        "# Initializing Classifiers\n",
        "clf1 = LogisticRegression(multi_class='multinomial',\n",
        "                          solver='newton-cg',\n",
        "                          max_iter=1000,\n",
        "                          random_state=1)\n",
        "clf2 = KNeighborsClassifier(algorithm='ball_tree',\n",
        "                            leaf_size=50)\n",
        "clf3 = DecisionTreeClassifier(random_state=1)\n",
        "clf4 = SVC(random_state=1)\n",
        "\n",
        "# build pipeline\n",
        "pipe1 = Pipeline([('std',StandardScaler()),\n",
        "                  ('clf1',clf1)])\n",
        "pipe2 = Pipeline([('std', StandardScaler()),\n",
        "                  ('clf2',clf2)])\n",
        "pipe4 = Pipeline([('std',StandardScaler()),\n",
        "                  ('clf4',clf4)])\n",
        "\n",
        "# setup the parameters grids\n",
        "param_grid1 = [{'clf1__penalty':['l2'],\n",
        "                'clf1__C':np.power(10.,np.arange(-4,4))}]\n",
        "\n",
        "param_grid2 = [{'clf2__n_neighbors':list(range(1,10)),\n",
        "                'clf2__p':[1,2]}]\n",
        "\n",
        "# set up multiple GridSearchCV objects, 1 for each algorithm\n",
        "gridcvs = {}\n",
        "\n",
        "for pgrid, est, name in zip((param_grid1,param_grid2),\n",
        "                            (pipe1,pipe2),\n",
        "                            ('Logistic','KNN')):\n",
        "  gcv = GridSearchCV(estimator=est,\n",
        "                     param_grid=pgrid,\n",
        "                     scoring='accuracy',\n",
        "                     n_jobs=1,\n",
        "                     cv=2,\n",
        "                     verbose=0,\n",
        "                     refit=True)\n",
        "  gridcvs[name] = gcv\n",
        "\n"
      ],
      "metadata": {
        "id": "W03WUVJL6uY8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = {name: [] for name, gs_est in gridcvs.items()}\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
        "\n",
        "# the outer loop for algorithm selection\n",
        "c = 1\n",
        "for outer_train_idx, outer_valid_idx in skfold.split(X_train, y_train):\n",
        "  for name, gs_est in sorted(gridcvs.items()):\n",
        "    print(f'outer fold {c}/5 | tuning {name:8s}',end='')\n",
        "\n",
        "    # The inner loop for hyperparameter tuning\n",
        "    gs_est.fit(X_train[outer_train_idx],y_train[outer_train_idx])\n",
        "    y_pred = gs_est.predict(X_train[outer_valid_idx])\n",
        "    acc = accuracy_score(y_true=y_train[outer_valid_idx], y_pred=y_pred)\n",
        "    print(f' | inner ACC {gs_est.best_score_:.2f} | outer ACC {acc * 100:.2f}')\n",
        "    cv_scores[name].append(acc)\n",
        "  c += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WprMegrl8tEm",
        "outputId": "276d80a9-cd0b-4ac5-c782-5841c6064149"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outer fold 1/5 | tuning KNN      | inner ACC 0.88 | outer ACC 91.62\n",
            "outer fold 1/5 | tuning Logistic | inner ACC 0.89 | outer ACC 90.00\n",
            "outer fold 2/5 | tuning KNN      | inner ACC 0.89 | outer ACC 91.88\n",
            "outer fold 2/5 | tuning Logistic | inner ACC 0.89 | outer ACC 91.00\n",
            "outer fold 3/5 | tuning KNN      | inner ACC 0.89 | outer ACC 90.88\n",
            "outer fold 3/5 | tuning Logistic | inner ACC 0.89 | outer ACC 90.00\n",
            "outer fold 4/5 | tuning KNN      | inner ACC 0.89 | outer ACC 90.88\n",
            "outer fold 4/5 | tuning Logistic | inner ACC 0.89 | outer ACC 90.75\n",
            "outer fold 5/5 | tuning KNN      | inner ACC 0.88 | outer ACC 90.25\n",
            "outer fold 5/5 | tuning Logistic | inner ACC 0.89 | outer ACC 89.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the results\n",
        "for name in cv_scores.keys():\n",
        "  print(f'{name:8s} | outer CV acc: {100* np.mean(cv_scores[name]):.2f} +/- {100*np.std(cv_scores[name]):.3f}')\n",
        "\n",
        "print(f'\\n Logistic Regression Best parameters {gridcvs[\"Logistic\"].best_params_}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op11LzrZIiO7",
        "outputId": "ba08f326-5c00-4046-a04d-a0ad7aa2b958"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic | outer CV acc: 90.25 +/- 0.548\n",
            "KNN      | outer CV acc: 91.10 +/- 0.583\n",
            "\n",
            " Logistic Regression Best parameters {'clf1__C': 0.01, 'clf1__penalty': 'l2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the models to the whole training set\n",
        "# using the 'best' hyperparameters\n",
        "for name in cv_scores.keys():\n",
        "  name_best_algo = gridcvs[name]\n",
        "\n",
        "  name_best_algo.fit(X_train, y_train)\n",
        "  train_acc = accuracy_score(y_true=y_train, \n",
        "                             y_pred=name_best_algo.predict(X_train))\n",
        "  test_acc = accuracy_score(y_true=y_test, \n",
        "                            y_pred=name_best_algo.predict(X_test))\n",
        "\n",
        "  print(f'Algorithm: {name:8s} Accuracy: {100 * name_best_algo.best_score_:.2f} (avg over CV test folds)')\n",
        "  print(f'Training Accuracy: {100 * train_acc:.2f}')\n",
        "  print(f'Test Accuracy: {100 * test_acc:.2f}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIRslYS7ANW7",
        "outputId": "fdf9afb5-c258-4d04-f786-cb3d63db0b3c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Accuracy: 89.22 (avg over CV test folds)\n",
            "Training Accuracy: 99.50\n",
            "Test Accuracy: 89.30\n",
            "KNN      Accuracy: 89.33 (avg over CV test folds)\n",
            "Training Accuracy: 100.00\n",
            "Test Accuracy: 91.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLbCMWj7MYri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}